<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Microsoft.ML.PCA</name>
    </assembly>
    <members>
        <member name="M:Microsoft.ML.PcaCatalog.ProjectToPrincipalComponents(Microsoft.ML.TransformsCatalog.ProjectionTransforms,System.String,System.String,System.String,System.Int32,System.Int32,System.Boolean,System.Nullable{System.Int32})">
            <summary>Initializes a new instance of <see cref="T:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator"/>.</summary>
            <param name="catalog">The transform's catalog.</param>
            <param name="outputColumnName">Name of the column resulting from the transformation of <paramref name="inputColumnName"/>.</param>
            <param name="inputColumnName">Name of column to transform. If set to <see langword="null"/>, the value of the <paramref name="outputColumnName"/> will be used as source.</param>
            <param name="exampleWeightColumnName">The name of the example weight column (optional).</param>
            <param name="rank">The number of principal components.</param>
            <param name="overSampling">Oversampling parameter for randomized PrincipalComponentAnalysis training.</param>
            <param name="center">If enabled, data is centered to be zero mean.</param>
            <param name="seed">The seed for random number generation.</param>
        </member>
        <member name="M:Microsoft.ML.PcaCatalog.ProjectToPrincipalComponents(Microsoft.ML.TransformsCatalog.ProjectionTransforms,Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.ColumnOptions[])">
            <summary>Initializes a new instance of <see cref="T:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator"/>.</summary>
            <param name="catalog">The transform's catalog.</param>
            <param name="columns">Input columns to apply PrincipalComponentAnalysis on.</param>
        </member>
        <member name="M:Microsoft.ML.PcaCatalog.RandomizedPca(Microsoft.ML.AnomalyDetectionCatalog.AnomalyDetectionTrainers,System.String,System.String,System.Int32,System.Int32,System.Boolean,System.Nullable{System.Int32})">
            <summary>
            Trains an approximate PCA using Randomized SVD algorithm.
            </summary>
            <param name="catalog">The anomaly detection catalog trainer object.</param>
            <param name="featureColumnName">The name of the feature column.</param>
            <param name="exampleWeightColumnName">The name of the example weight column (optional).</param>
            <param name="rank">The number of components in the PCA.</param>
            <param name="oversampling">Oversampling parameter for randomized PCA training.</param>
            <param name="center">If enabled, data is centered to be zero mean.</param>
            <param name="seed">The seed for random number generation.</param>
        </member>
        <member name="M:Microsoft.ML.PcaCatalog.RandomizedPca(Microsoft.ML.AnomalyDetectionCatalog.AnomalyDetectionTrainers,Microsoft.ML.Trainers.RandomizedPcaTrainer.Options)">
            <summary>
            Trains an approximate PCA using Randomized SVD algorithm.
            </summary>
            <param name="catalog">The anomaly detection catalog trainer object.</param>
            <param name="options">Advanced options to the algorithm.</param>
        </member>
        <member name="T:Microsoft.ML.Trainers.RandomizedPcaTrainer">
            <summary>
            This trainer trains an approximate PCA using Randomized SVD algorithm
            Reference: https://web.stanford.edu/group/mmds/slides2010/Martinsson.pdf
            </summary>
            <remarks>
            This PCA can be made into Kernel PCA by using Random Fourier Features transform
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Trainers.RandomizedPcaTrainer.#ctor(Microsoft.ML.IHostEnvironment,System.String,System.String,System.Int32,System.Int32,System.Boolean,System.Nullable{System.Int32})">
            <summary>
            Initializes a new instance of <see cref="T:Microsoft.ML.Trainers.RandomizedPcaTrainer"/>.
            </summary>
            <param name="env">The local instance of the <see cref="T:Microsoft.ML.IHostEnvironment"/>.</param>
            <param name="features">The name of the feature column.</param>
            <param name="weights">The name of the weight column.</param>
            <param name="rank">The number of components in the PCA.</param>
            <param name="oversampling">Oversampling parameter for randomized PCA training.</param>
            <param name="center">If enabled, data is centered to be zero mean.</param>
            <param name="seed">The seed for random number generation.</param>
        </member>
        <member name="M:Microsoft.ML.Trainers.RandomizedPcaTrainer.PostProcess(System.Single[][],System.Single[],System.Single[],System.Int32,System.Int32)">
            <summary>
            Modifies <paramref name="y"/> in place so it becomes <paramref name="y"/> * eigenvectors / eigenvalues.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Trainers.PcaModelParameters">
            <summary>
        PCA is a dimensionality-reduction transform which computes the projection of the feature vector onto a low-rank subspace. 
      </summary><remarks>
      <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principle Component Analysis (PCA)</a> is a dimensionality-reduction algorithm which computes the projection of the feature vector to onto a low-rank subspace.
      Its training is done using the technique described in the paper: <a href="https://arxiv.org/pdf/1310.6304v2.pdf">Combining Structured and Unstructured Randomness in Large Scale PCA</a>,
      and the paper <a href="https://arxiv.org/pdf/0909.4061v2.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
        <para>For more information, see also:</para>
        <list type="bullet">
          <item><description>
            <a href="https://web.stanford.edu/group/mmds/slides2010/Martinsson.pdf">Randomized Methods for Computing the Singular Value Decomposition (SVD) of very large matrices</a>
          </description></item>
          <item><description>
            <a href="https://arxiv.org/abs/0809.2274">A randomized algorithm for principal component analysis</a>
          </description></item>
          <item><description>
            <a href="http://users.cms.caltech.edu/~jtropp/papers/HMT11-Finding-Structure-SIREV.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
          </description></item>
        </list>
      </remarks>
        </member>
        <member name="M:Microsoft.ML.Trainers.PcaModelParameters.#ctor(Microsoft.ML.IHostEnvironment,System.Int32,System.Single[][],Microsoft.ML.Data.VBuffer{System.Single}@)">
            <summary>
            Instantiate new model parameters from trained model.
            </summary>
            <param name="env">The host environment.</param>
            <param name="rank">The rank of the PCA approximation of the covariance matrix. This is the number of eigenvectors in the model.</param>
            <param name="eigenVectors">Array of eigenvectors.</param>
            <param name="mean">The mean vector of the training data.</param>
        </member>
        <member name="M:Microsoft.ML.Trainers.PcaModelParameters.GetEigenVectors(Microsoft.ML.Data.VBuffer{System.Single}[]@,System.Int32@)">
            <summary>
            Copies the top eigenvectors of the covariance matrix of the training data
            into a set of buffers.
            </summary>
            <param name="vectors">A possibly reusable set of vectors, which will
            be expanded as necessary to accomodate the data.</param>
            <param name="rank">Set to the rank, which is also the logical length
            of <paramref name="vectors"/>.</param>
        </member>
        <member name="M:Microsoft.ML.Trainers.PcaModelParameters.GetMean(Microsoft.ML.Data.VBuffer{System.Single}@)">
            <summary>
            Copies the mean vector of the training data.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Transforms.PrincipalComponentAnalysisTransformer">
            <summary>
        PCA is a dimensionality-reduction transform which computes the projection of the feature vector onto a low-rank subspace. 
      </summary><remarks>
      <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principle Component Analysis (PCA)</a> is a dimensionality-reduction algorithm which computes the projection of the feature vector to onto a low-rank subspace.
      Its training is done using the technique described in the paper: <a href="https://arxiv.org/pdf/1310.6304v2.pdf">Combining Structured and Unstructured Randomness in Large Scale PCA</a>,
      and the paper <a href="https://arxiv.org/pdf/0909.4061v2.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
        <para>For more information, see also:</para>
        <list type="bullet">
          <item><description>
            <a href="https://web.stanford.edu/group/mmds/slides2010/Martinsson.pdf">Randomized Methods for Computing the Singular Value Decomposition (SVD) of very large matrices</a>
          </description></item>
          <item><description>
            <a href="https://arxiv.org/abs/0809.2274">A randomized algorithm for principal component analysis</a>
          </description></item>
          <item><description>
            <a href="http://users.cms.caltech.edu/~jtropp/papers/HMT11-Finding-Structure-SIREV.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
          </description></item>
        </list>
      </remarks>
        </member>
        <member name="T:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator">
            <summary>
        PCA is a dimensionality-reduction transform which computes the projection of the feature vector onto a low-rank subspace. 
      </summary><remarks>
      <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principle Component Analysis (PCA)</a> is a dimensionality-reduction algorithm which computes the projection of the feature vector to onto a low-rank subspace.
      Its training is done using the technique described in the paper: <a href="https://arxiv.org/pdf/1310.6304v2.pdf">Combining Structured and Unstructured Randomness in Large Scale PCA</a>,
      and the paper <a href="https://arxiv.org/pdf/0909.4061v2.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
        <para>For more information, see also:</para>
        <list type="bullet">
          <item><description>
            <a href="https://web.stanford.edu/group/mmds/slides2010/Martinsson.pdf">Randomized Methods for Computing the Singular Value Decomposition (SVD) of very large matrices</a>
          </description></item>
          <item><description>
            <a href="https://arxiv.org/abs/0809.2274">A randomized algorithm for principal component analysis</a>
          </description></item>
          <item><description>
            <a href="http://users.cms.caltech.edu/~jtropp/papers/HMT11-Finding-Structure-SIREV.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
          </description></item>
        </list>
      </remarks>
        </member>
        <member name="T:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.ColumnOptions">
            <summary>
            Describes how the transformer handles one column pair.
            </summary>
        </member>
        <member name="F:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.ColumnOptions.Name">
            <summary>
            Name of the column resulting from the transformation of <see cref="F:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.ColumnOptions.InputColumnName"/>.
            </summary>
        </member>
        <member name="F:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.ColumnOptions.InputColumnName">
            <summary>
            Name of column to transform.
            </summary>
        </member>
        <member name="F:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.ColumnOptions.WeightColumn">
            <summary>
            The name of the weight column.
            </summary>
        </member>
        <member name="F:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.ColumnOptions.Rank">
            <summary>
            The number of components in the PCA.
            </summary>
        </member>
        <member name="F:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.ColumnOptions.Oversampling">
            <summary>
            Oversampling parameter for randomized PCA training.
            </summary>
        </member>
        <member name="F:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.ColumnOptions.Center">
            <summary>
            If enabled, data is centered to be zero mean.
            </summary>
        </member>
        <member name="F:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.ColumnOptions.Seed">
            <summary>
            The seed for random number generation.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.ColumnOptions.#ctor(System.String,System.String,System.String,System.Int32,System.Int32,System.Boolean,System.Nullable{System.Int32})">
            <summary>
            Describes how the transformer handles one column pair.
            </summary>
            <param name="name">Name of the column resulting from the transformation of <paramref name="inputColumnName"/>.</param>
            <param name="inputColumnName">Name of column to transform.
            If set to <see langword="null"/>, the value of the <paramref name="name"/> will be used as source.</param>
            <param name="weightColumn">The name of the weight column.</param>
            <param name="rank">The number of components in the PCA.</param>
            <param name="overSampling">Oversampling parameter for randomized PCA training.</param>
            <param name="center">If enabled, data is centered to be zero mean.</param>
            <param name="seed">The random seed. If unspecified random state will be instead derived from the <see cref="T:Microsoft.ML.MLContext"/>.</param>
        </member>
        <member name="M:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.#ctor(Microsoft.ML.IHostEnvironment,System.String,System.String,System.String,System.Int32,System.Int32,System.Boolean,System.Nullable{System.Int32})">
            <summary>
        PCA is a dimensionality-reduction transform which computes the projection of the feature vector onto a low-rank subspace. 
      </summary><remarks>
      <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principle Component Analysis (PCA)</a> is a dimensionality-reduction algorithm which computes the projection of the feature vector to onto a low-rank subspace.
      Its training is done using the technique described in the paper: <a href="https://arxiv.org/pdf/1310.6304v2.pdf">Combining Structured and Unstructured Randomness in Large Scale PCA</a>,
      and the paper <a href="https://arxiv.org/pdf/0909.4061v2.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
        <para>For more information, see also:</para>
        <list type="bullet">
          <item><description>
            <a href="https://web.stanford.edu/group/mmds/slides2010/Martinsson.pdf">Randomized Methods for Computing the Singular Value Decomposition (SVD) of very large matrices</a>
          </description></item>
          <item><description>
            <a href="https://arxiv.org/abs/0809.2274">A randomized algorithm for principal component analysis</a>
          </description></item>
          <item><description>
            <a href="http://users.cms.caltech.edu/~jtropp/papers/HMT11-Finding-Structure-SIREV.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
          </description></item>
        </list>
      </remarks>
            <param name="env">The environment to use.</param>
            <param name="outputColumnName">Name of the column resulting from the transformation of <paramref name="inputColumnName" />.</param>
            <param name="inputColumnName">Name of the column to transform.
            If set to <see langword="null" />, the value of the <paramref name="outputColumnName" /> will be used as source.</param>
            <param name="weightColumn">The name of the weight column.</param>
            <param name="rank">The number of components in the PCA.</param>
            <param name="overSampling">Oversampling parameter for randomized PCA training.</param>
            <param name="center">If enabled, data is centered to be zero mean.</param>
            <param name="seed">The seed for random number generation.</param>
        </member>
        <member name="M:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.#ctor(Microsoft.ML.IHostEnvironment,Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.ColumnOptions[])">
            <summary>
        PCA is a dimensionality-reduction transform which computes the projection of the feature vector onto a low-rank subspace. 
      </summary><remarks>
      <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principle Component Analysis (PCA)</a> is a dimensionality-reduction algorithm which computes the projection of the feature vector to onto a low-rank subspace.
      Its training is done using the technique described in the paper: <a href="https://arxiv.org/pdf/1310.6304v2.pdf">Combining Structured and Unstructured Randomness in Large Scale PCA</a>,
      and the paper <a href="https://arxiv.org/pdf/0909.4061v2.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
        <para>For more information, see also:</para>
        <list type="bullet">
          <item><description>
            <a href="https://web.stanford.edu/group/mmds/slides2010/Martinsson.pdf">Randomized Methods for Computing the Singular Value Decomposition (SVD) of very large matrices</a>
          </description></item>
          <item><description>
            <a href="https://arxiv.org/abs/0809.2274">A randomized algorithm for principal component analysis</a>
          </description></item>
          <item><description>
            <a href="http://users.cms.caltech.edu/~jtropp/papers/HMT11-Finding-Structure-SIREV.pdf">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</a>
          </description></item>
        </list>
      </remarks>
            <param name="env">The environment to use.</param>
            <param name="columns">The dataset columns to use, and their specific settings.</param>
        </member>
        <member name="M:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.Fit(Microsoft.Data.DataView.IDataView)">
            <summary>
            Trains and returns a <see cref="T:Microsoft.ML.Transforms.PrincipalComponentAnalysisTransformer"/>.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Transforms.PrincipalComponentAnalysisEstimator.GetOutputSchema(Microsoft.ML.SchemaShape)">
            <summary>
            Returns the <see cref="T:Microsoft.ML.SchemaShape"/> of the schema which will be produced by the transformer.
            Used for schema propagation and verification in a pipeline.
            </summary>
        </member>
    </members>
</doc>
